{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuroM Tutorial Notebook\n",
    "\n",
    "NeuroM contains helper functions that allow to easily load neuronal morphologies from files into NeuroM data structures. It also provides convenient methods to query various properties of the morphologies, as well as an easy way to visualize morphological objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install NeuroM[plotly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import neurom module\n",
    "import neurom as nm\n",
    "# Import neurom visualization module\n",
    "from neurom import viewer\n",
    "from neurom.view import plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading a morphology or a population\n",
    "\n",
    "NeuroM can load morphologies from swc, h5 or NL ascii files. Please note that the Neurolucida ascii reader is experimental! There are no guarantees regarding correctness of loading data from files in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single morphology  \n",
    "neuron = nm.load_neuron('../tests/data/valid_set/Neuron.swc')\n",
    "\n",
    "# Load a population of morphologies from a set of files\n",
    "pop = nm.load_neurons('../tests/data/valid_set/')\n",
    "\n",
    "# Get a single morphology from the population\n",
    "single_neuron = pop.neurons[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Morphology visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a morphology in two dimensions\n",
    "fig, ax = plotly.draw(neuron, plane='xy', inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a morphology in three dimensions\n",
    "fig, ax = plotly.draw(neuron, inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a single tree in three dimensions\n",
    "fig, ax = plotly.draw(neuron.neurites[0], inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dendrogram of a morphology\n",
    "fig, ax = viewer.draw(neuron, mode='dendrogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Morphology analysis\n",
    "\n",
    "### 3.1 Morphometrics extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the total number of neurites (basal and apical dendrites, and axons)\n",
    "number_of_neurites = nm.get('number_of_neurites', neuron)\n",
    "\n",
    "# Extract the total number of sections\n",
    "number_of_sections = nm.get('number_of_sections', neuron)\n",
    "\n",
    "# Extract the soma radius\n",
    "soma_radius = neuron.soma.radius\n",
    "\n",
    "# Extract the number of sections per neurite\n",
    "number_of_sections_per_neurite = nm.get('number_of_sections_per_neurite', neuron)\n",
    "\n",
    "# Print result\n",
    "print(\"Neuron id          : {0} \\n\\\n",
    "Number of neurites : {1} \\n\\\n",
    "Soma radius        : {2:.2f} \\n\\\n",
    "Number of sections : {3}\".format(neuron.name, number_of_neurites[0], soma_radius, number_of_sections[0]))\n",
    "print()\n",
    "print(\"Neurite type \\t\\t\\t| Number of sections\")\n",
    "for i, neurite in enumerate(neuron.neurites):    \n",
    "    print(\"{0:31} | {1}\".format(str(neurite.type), number_of_sections_per_neurite[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the lengths of the sections\n",
    "section_lengths = nm.get('section_lengths', neuron)\n",
    "\n",
    "# Extract the lengths of the segments\n",
    "segment_lengths = nm.get('segment_lengths', neuron)\n",
    "\n",
    "# Extract the local bifurcation angles\n",
    "local_bif_angles = nm.get('local_bifurcation_angles', neuron)\n",
    "\n",
    "# Extract the remote bifurcation angles\n",
    "remote_bif_angles = nm.get('remote_bifurcation_angles', neuron)\n",
    "\n",
    "# Extract the radial distances of the sections\n",
    "section_radial_distances = nm.get('section_radial_distances', neuron)\n",
    "\n",
    "# Extract the path distances of the sections\n",
    "section_path_distances = nm.get('section_path_distances', neuron)\n",
    "\n",
    "# Print result\n",
    "features = (segment_lengths, section_lengths, local_bif_angles, \n",
    "            remote_bif_angles, section_path_distances, section_radial_distances)\n",
    "\n",
    "def check(feature_list, n): \n",
    "    return '{0:.2f}'.format(feature_list[n]) if n < len(feature_list) else ''\n",
    "\n",
    "print('|sg_len|sc_len|lc_bif_angles|rm_bif_angles|sc_path_dists|sc_rad_dists|')\n",
    "for n in range(0, 50):\n",
    "    args = (check(f, n) for f in features)\n",
    "    print('|{0:^6}|{1:^6}|{2:^13}|{3:^13}|{4:^13}|{5:^12}|'.format(*args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Analyze different types of trees\n",
    "\n",
    "The previous examples treated all neurites in the same way. NeuroM allows you to extract morphometrics for a selected type of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the section lengths of axonal trees\n",
    "ax_section_lengths = nm.get('section_lengths', neuron, neurite_type=nm.AXON)\n",
    "\n",
    "# Extract the section lengths of basal dendrite trees\n",
    "ba_section_lengths = nm.get('section_lengths', neuron, neurite_type=nm.BASAL_DENDRITE)\n",
    "\n",
    "# Extract the section lengths of apical dendrite trees\n",
    "ap_section_lengths = nm.get('section_lengths', neuron, neurite_type=nm.APICAL_DENDRITE)\n",
    "\n",
    "print('\\nAxonal section lengths = ', ax_section_lengths)\n",
    "print('\\nBasal section lengths =  ', ba_section_lengths)\n",
    "print('\\nApical section lengths = ', ap_section_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Perform statistical analysis on extracted measurements\n",
    "\n",
    "Now we are ready to extract basic statistical measurements, using common Python functions. For this, we will use [`numpy`](http://www.numpy.org/), which is a package for scientific computing with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We can get the mean section length\n",
    "mean_sl = np.mean(section_lengths)\n",
    "\n",
    "# We can get the standard deviation of the section lengths\n",
    "std_sl = np.std(section_lengths)\n",
    "\n",
    "# We can get the minimum section length\n",
    "min_sl = np.min(section_lengths)\n",
    "\n",
    "# ... and the maximum section length\n",
    "max_sl = np.max(section_lengths)\n",
    "\n",
    "print('Section length statistics:')\n",
    "print('  [mean, std] = [{0:.2f}, {1:.2f}]'.format(mean_sl, std_sl))\n",
    "print('  [min, max]: [{0:.2f}, {1:.2f}]'.format(min_sl, max_sl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Generate plots from the extracted morphometrics\n",
    "\n",
    "The distribution of the extracted measurements can be plotted with [`matplotlib`](http://matplotlib.org/), which is a Python library for plot generation. We will use the [`matplotlib.pyplot`](http://matplotlib.org/api/pyplot_api.html) sub module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the feature of choice\n",
    "feature = nm.get('segment_lengths', neuron)\n",
    "\n",
    "# Create empty figure\n",
    "fig = plt.figure(figsize=(11,3))\n",
    "\n",
    "# Create histogram\n",
    "ax = fig.add_subplot('131')\n",
    "ax.hist(feature, bins=25, edgecolor='black')\n",
    "\n",
    "# Create cumulative histogram\n",
    "ax = fig.add_subplot('132')\n",
    "ax.hist(feature, bins=25, cumulative=True, edgecolor='black')\n",
    "\n",
    "# Create boxplot; flier points are indicated with green dots\n",
    "ax = fig.add_subplot('133')\n",
    "_ = ax.boxplot(feature, sym='g.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Fit the extracted data with a statistical distribution\n",
    "\n",
    "Now we are ready to fit the extracted data using common Python functions. For this, we will use [`scipy`](http://www.scipy.org/), which is a package for numerical routines for scientific computing with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurom import stats\n",
    "\n",
    "data = nm.get('segment_lengths', neuron)\n",
    "\n",
    "# Letâ€™s start with a normal distribution. We will fit the data that we extracted above with a normal distribution\n",
    "p = stats.fit(data, distribution='norm')\n",
    "\n",
    "# The output of the function is a named tuple of type FitResults\n",
    "print('Fit output type : ', type(p))\n",
    "\n",
    "# The parameters are stored in the variable params, which in the case of the normal distribution stores the mu and sigma\n",
    "# of the normal distribution\n",
    "mu, sigma = p.params\n",
    "ks_dist, pvalue = p.errs\n",
    "\n",
    "# Print result\n",
    "print('[mu, sigma] : [{0:.2f}, {1:.2f}]\\n'.format(mu, sigma))\n",
    "\n",
    "# We need to check the statistical error of the performed fit to evaluate the accuracy of the \n",
    "# selected model. To do so we use the errors variable of FitResults:\n",
    "print('Kolmogorov-Smirnov distance : {0:.2f}'.format(ks_dist))\n",
    "print('P-value : {0:.2f}'.format(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the fitting can be visualized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Create a histogram as above\n",
    "fig = plt.figure()\n",
    "plt.hist(data, bins=25, density=True, edgecolor='black')\n",
    "\n",
    "# Plot range: 5 standard deviations around the mean\n",
    "norm_range = np.arange(mu - 5.*sigma, mu + 5.*sigma, 0.001)\n",
    "\n",
    "# Plot the normal pdf with the given range, mu and sigma\n",
    "_ = plt.plot(norm_range, norm.pdf(norm_range, mu, sigma), linewidth=3., c='r', alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to find the optimal distribution that best fits the data, among a number of distributions that are\n",
    "supported by `scipy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = stats.optimal_distribution(data, distr_to_check=('lognorm', 'logistic', 'norm'))\n",
    "print('Fit results:', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Apply more advanced manipulation on extracted data\n",
    "\n",
    "In this example, we extract all section lengths that exceed a selected threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold value\n",
    "threshold = 10\n",
    "\n",
    "# Get the ids of sections which length exceeds the threshold\n",
    "selected_ids = np.where(section_lengths > threshold)\n",
    "\n",
    "# Get the values of section lengths that exceed the threshold\n",
    "section_lengths[selected_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Combine morphometrics\n",
    "\n",
    "We can study relations between different morphometrics. For example, we can combine section length and path length to soma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the length of all sections with a radial distance between 0.0 and 60.0\n",
    "section_indices = np.where((section_radial_distances >= 0.0) & (section_radial_distances < 60.0))\n",
    "selected_section_lengths = section_lengths[section_indices]\n",
    "print(selected_section_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
